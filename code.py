# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L1U_RIcJJZvwnPHut-yP3NMgYxK2de6x
"""

# BigMart Sales Prediction Notebook

# 1. Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# 2. Load the Data

train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

# 3. Exploratory Data Analysis
print("Train Data Shape:", train_df.shape)
print("Test Data Shape:", test_df.shape)
print("\nTrain Data Info:")
print(train_df.info())
print("\nMissing Values in Train Data:")
print(train_df.isnull().sum())

# Visualize distribution of target variable (Item_Outlet_Sales)
plt.figure(figsize=(10,6))
sns.histplot(train_df['Item_Outlet_Sales'], bins=50)
plt.title('Distribution of Item Outlet Sales')
plt.show()

# 4. Data Preprocessing
# Handle missing values
# Item_Weight: fill with mean
train_df['Item_Weight'].fillna(train_df['Item_Weight'].mean(), inplace=True)
test_df['Item_Weight'].fillna(test_df['Item_Weight'].mean(), inplace=True)

# Outlet_Size: fill with mode
train_df['Outlet_Size'].fillna(train_df['Outlet_Size'].mode()[0], inplace=True)
test_df['Outlet_Size'].fillna(test_df['Outlet_Size'].mode()[0], inplace=True)

# 5. Feature Engineering
# Create new feature: Outlet_Age
train_df['Outlet_Age'] = 2013 - train_df['Outlet_Establishment_Year']
test_df['Outlet_Age'] = 2013 - test_df['Outlet_Establishment_Year']

# Encode categorical variables
le = LabelEncoder()
categorical_cols = ['Item_Fat_Content', 'Item_Type', 'Outlet_Identifier',
                   'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']

for col in categorical_cols:
    train_df[col] = le.fit_transform(train_df[col])
    test_df[col] = le.transform(test_df[col])

# 6. Prepare features and target
X = train_df.drop(['Item_Identifier', 'Outlet_Establishment_Year', 'Item_Outlet_Sales'], axis=1)
y = train_df['Item_Outlet_Sales']
X_test = test_df.drop(['Item_Identifier', 'Outlet_Establishment_Year'], axis=1)

# 7. Split the training data for validation
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# 8. Build and Train Model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# 9. Model Evaluation
y_pred = rf_model.predict(X_val)
rmse = np.sqrt(mean_squared_error(y_val, y_pred))
print(f"Root Mean Squared Error on Validation Set: {rmse}")

# Feature Importance
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_model.feature_importances_
})
feature_importance = feature_importance.sort_values('importance', ascending=False)

plt.figure(figsize=(10,6))
sns.barplot(x='importance', y='feature', data=feature_importance)
plt.title('Feature Importance')
plt.show()

# 10. Make Predictions on Test Set
test_predictions = rf_model.predict(X_test)

# 11. Create Submission File
submission = pd.DataFrame({
    'Item_Identifier': test_df['Item_Identifier'],
    'Outlet_Identifier': test_df['Outlet_Identifier'],
    'Item_Outlet_Sales': test_predictions
})
submission.to_csv('submission.csv', index=False)
print("Submission file created successfully")